{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9668900",
   "metadata": {},
   "source": [
    "Given a list of planets discovered by KEPLER.\n",
    "\n",
    "Create an ML algorithm to classify the planets as Candidate/False positive/Confirmed etc based on the  column “koi_disposition”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7673d55",
   "metadata": {},
   "source": [
    "Project Workflow -\n",
    "\n",
    "1. Importing required packages\n",
    "\n",
    "2. Dataset Loading\n",
    "\n",
    "3. Preparing the dataset by using certain processing techniques like  checking the statsitics of dataset, mapping categorical features into numeric, replacing the NAN values with mean data\n",
    "\n",
    "4. Differentiating the features into training and testing data and loading into the models for Classification\n",
    "\n",
    "5. Random Forest Classifier and Logistic Regression is used for classification purposes \n",
    "\n",
    "6. Test Evaluation metrics is checked like accuracy, classification report and confusion matrix for understanding how both the algorithms performs on the test data\n",
    "\n",
    "7. Finally one bar graph is plotted for Accuracy score comparison which finally concludes the problem statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1df0f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6aa09ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"/Users/soumobratamanna/Dropbox/Data_Science_Projects/tensorflow-test/Planets_Dataset_Classification.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e187e88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>291.93</td>\n",
       "      <td>48.14</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>291.93</td>\n",
       "      <td>48.14</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>297.00</td>\n",
       "      <td>48.13</td>\n",
       "      <td>15.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>285.53</td>\n",
       "      <td>48.29</td>\n",
       "      <td>15.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>288.75</td>\n",
       "      <td>48.23</td>\n",
       "      <td>15.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      kepid kepoi_name   kepler_name koi_disposition koi_pdisposition  \\\n",
       "0  10797460  K00752.01  Kepler-227 b       CONFIRMED        CANDIDATE   \n",
       "1  10797460  K00752.02  Kepler-227 c       CONFIRMED        CANDIDATE   \n",
       "2  10811496  K00753.01           NaN       CANDIDATE        CANDIDATE   \n",
       "3  10848459  K00754.01           NaN  FALSE POSITIVE   FALSE POSITIVE   \n",
       "4  10854555  K00755.01  Kepler-664 b       CONFIRMED        CANDIDATE   \n",
       "\n",
       "   koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  ...  \\\n",
       "0      1.000              0              0              0              0  ...   \n",
       "1      0.969              0              0              0              0  ...   \n",
       "2      0.000              0              0              0              0  ...   \n",
       "3      0.000              0              1              0              0  ...   \n",
       "4      1.000              0              0              0              0  ...   \n",
       "\n",
       "   koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  koi_srad  \\\n",
       "0           -81.0       4.47            0.06           -0.10      0.93   \n",
       "1           -81.0       4.47            0.06           -0.10      0.93   \n",
       "2          -176.0       4.54            0.04           -0.18      0.87   \n",
       "3          -174.0       4.56            0.05           -0.17      0.79   \n",
       "4          -211.0       4.44            0.07           -0.21      1.05   \n",
       "\n",
       "   koi_srad_err1  koi_srad_err2      ra    dec  koi_kepmag  \n",
       "0           0.11          -0.06  291.93  48.14       15.35  \n",
       "1           0.11          -0.06  291.93  48.14       15.35  \n",
       "2           0.23          -0.08  297.00  48.13       15.44  \n",
       "3           0.20          -0.07  285.53  48.29       15.60  \n",
       "4           0.33          -0.13  288.75  48.23       15.51  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d98f6a55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>10130039</td>\n",
       "      <td>K01909.02</td>\n",
       "      <td>Kepler-334 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>287.14</td>\n",
       "      <td>47.12</td>\n",
       "      <td>12.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>9518318</td>\n",
       "      <td>K01978.01</td>\n",
       "      <td>Kepler-346 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>288.01</td>\n",
       "      <td>46.12</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>9518318</td>\n",
       "      <td>K01978.02</td>\n",
       "      <td>Kepler-346 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>288.01</td>\n",
       "      <td>46.12</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>7273277</td>\n",
       "      <td>K01979.01</td>\n",
       "      <td>Kepler-1035 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>289.04</td>\n",
       "      <td>42.88</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>11769890</td>\n",
       "      <td>K01980.01</td>\n",
       "      <td>Kepler-1036 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>295.18</td>\n",
       "      <td>49.95</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         kepid kepoi_name    kepler_name koi_disposition koi_pdisposition  \\\n",
       "1442  10130039  K01909.02   Kepler-334 b       CONFIRMED        CANDIDATE   \n",
       "1443   9518318  K01978.01   Kepler-346 b       CONFIRMED        CANDIDATE   \n",
       "1444   9518318  K01978.02   Kepler-346 c       CONFIRMED        CANDIDATE   \n",
       "1445   7273277  K01979.01  Kepler-1035 b       CONFIRMED        CANDIDATE   \n",
       "1446  11769890  K01980.01  Kepler-1036 b       CONFIRMED        CANDIDATE   \n",
       "\n",
       "      koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "1442      1.000              0              0              0              0   \n",
       "1443      1.000              0              0              0              0   \n",
       "1444      1.000              0              0              0              0   \n",
       "1445      0.998              0              0              0              0   \n",
       "1446      1.000              0              0              0              0   \n",
       "\n",
       "      ...  koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  \\\n",
       "1442  ...          -115.0       4.34            0.13           -0.10   \n",
       "1443  ...          -232.0       4.47            0.06           -0.21   \n",
       "1444  ...          -232.0       4.47            0.06           -0.21   \n",
       "1445  ...           -87.0       4.46            0.04           -0.12   \n",
       "1446  ...          -107.0       4.51            0.05           -0.08   \n",
       "\n",
       "      koi_srad  koi_srad_err1  koi_srad_err2      ra    dec  koi_kepmag  \n",
       "1442      1.10           0.17          -0.16  287.14  47.12       12.78  \n",
       "1443      1.00           0.33          -0.11  288.01  46.12       15.21  \n",
       "1444      1.00           0.33          -0.11  288.01  46.12       15.21  \n",
       "1445      0.99           0.15          -0.07  289.04  42.88       12.99  \n",
       "1446      0.86           0.09          -0.05  295.18  49.95       13.80  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b5e98411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kepid                  0\n",
       "kepoi_name             0\n",
       "kepler_name          641\n",
       "koi_disposition        0\n",
       "koi_pdisposition       0\n",
       "koi_score             59\n",
       "koi_fpflag_nt          0\n",
       "koi_fpflag_ss          0\n",
       "koi_fpflag_co          0\n",
       "koi_fpflag_ec          0\n",
       "koi_period             0\n",
       "koi_period_err1       21\n",
       "koi_period_err2       21\n",
       "koi_time0bk            0\n",
       "koi_time0bk_err1      21\n",
       "koi_time0bk_err2      21\n",
       "koi_impact            18\n",
       "koi_impact_err1       21\n",
       "koi_impact_err2       21\n",
       "koi_duration           0\n",
       "koi_duration_err1     21\n",
       "koi_duration_err2     21\n",
       "koi_depth             18\n",
       "koi_depth_err1        21\n",
       "koi_depth_err2        21\n",
       "koi_prad              18\n",
       "koi_prad_err1         18\n",
       "koi_prad_err2         18\n",
       "koi_teq               18\n",
       "koi_insol             17\n",
       "koi_insol_err1        17\n",
       "koi_insol_err2        17\n",
       "koi_model_snr         18\n",
       "koi_tce_plnt_num      51\n",
       "koi_steff             18\n",
       "koi_steff_err1        20\n",
       "koi_steff_err2        24\n",
       "koi_slogg             18\n",
       "koi_slogg_err1        20\n",
       "koi_slogg_err2        20\n",
       "koi_srad              18\n",
       "koi_srad_err1         20\n",
       "koi_srad_err2         20\n",
       "ra                     0\n",
       "dec                    0\n",
       "koi_kepmag             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf12f90",
   "metadata": {},
   "source": [
    "Replacing the Null values with thier respective mean data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f399cc86",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/px/s9gf__z95vqfkz8lnyxs71w00000gn/T/ipykernel_1784/2083762864.py:1: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "  df_filled = data.fillna(data.mean())\n"
     ]
    }
   ],
   "source": [
    "df_filled = data.fillna(data.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "121d05a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>kepoi_name</th>\n",
       "      <th>kepler_name</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_pdisposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.01</td>\n",
       "      <td>Kepler-227 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>291.93</td>\n",
       "      <td>48.14</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>K00752.02</td>\n",
       "      <td>Kepler-227 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>291.93</td>\n",
       "      <td>48.14</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>K00753.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>297.00</td>\n",
       "      <td>48.13</td>\n",
       "      <td>15.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>K00754.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>FALSE POSITIVE</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>285.53</td>\n",
       "      <td>48.29</td>\n",
       "      <td>15.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>K00755.01</td>\n",
       "      <td>Kepler-664 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>288.75</td>\n",
       "      <td>48.23</td>\n",
       "      <td>15.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>10130039</td>\n",
       "      <td>K01909.02</td>\n",
       "      <td>Kepler-334 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>287.14</td>\n",
       "      <td>47.12</td>\n",
       "      <td>12.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>9518318</td>\n",
       "      <td>K01978.01</td>\n",
       "      <td>Kepler-346 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>288.01</td>\n",
       "      <td>46.12</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>9518318</td>\n",
       "      <td>K01978.02</td>\n",
       "      <td>Kepler-346 c</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>288.01</td>\n",
       "      <td>46.12</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>7273277</td>\n",
       "      <td>K01979.01</td>\n",
       "      <td>Kepler-1035 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>289.04</td>\n",
       "      <td>42.88</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>11769890</td>\n",
       "      <td>K01980.01</td>\n",
       "      <td>Kepler-1036 b</td>\n",
       "      <td>CONFIRMED</td>\n",
       "      <td>CANDIDATE</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>295.18</td>\n",
       "      <td>49.95</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1447 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         kepid kepoi_name    kepler_name koi_disposition koi_pdisposition  \\\n",
       "0     10797460  K00752.01   Kepler-227 b       CONFIRMED        CANDIDATE   \n",
       "1     10797460  K00752.02   Kepler-227 c       CONFIRMED        CANDIDATE   \n",
       "2     10811496  K00753.01            NaN       CANDIDATE        CANDIDATE   \n",
       "3     10848459  K00754.01            NaN  FALSE POSITIVE   FALSE POSITIVE   \n",
       "4     10854555  K00755.01   Kepler-664 b       CONFIRMED        CANDIDATE   \n",
       "...        ...        ...            ...             ...              ...   \n",
       "1442  10130039  K01909.02   Kepler-334 b       CONFIRMED        CANDIDATE   \n",
       "1443   9518318  K01978.01   Kepler-346 b       CONFIRMED        CANDIDATE   \n",
       "1444   9518318  K01978.02   Kepler-346 c       CONFIRMED        CANDIDATE   \n",
       "1445   7273277  K01979.01  Kepler-1035 b       CONFIRMED        CANDIDATE   \n",
       "1446  11769890  K01980.01  Kepler-1036 b       CONFIRMED        CANDIDATE   \n",
       "\n",
       "      koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  koi_fpflag_ec  \\\n",
       "0         1.000              0              0              0              0   \n",
       "1         0.969              0              0              0              0   \n",
       "2         0.000              0              0              0              0   \n",
       "3         0.000              0              1              0              0   \n",
       "4         1.000              0              0              0              0   \n",
       "...         ...            ...            ...            ...            ...   \n",
       "1442      1.000              0              0              0              0   \n",
       "1443      1.000              0              0              0              0   \n",
       "1444      1.000              0              0              0              0   \n",
       "1445      0.998              0              0              0              0   \n",
       "1446      1.000              0              0              0              0   \n",
       "\n",
       "      ...  koi_steff_err2  koi_slogg  koi_slogg_err1  koi_slogg_err2  \\\n",
       "0     ...           -81.0       4.47            0.06           -0.10   \n",
       "1     ...           -81.0       4.47            0.06           -0.10   \n",
       "2     ...          -176.0       4.54            0.04           -0.18   \n",
       "3     ...          -174.0       4.56            0.05           -0.17   \n",
       "4     ...          -211.0       4.44            0.07           -0.21   \n",
       "...   ...             ...        ...             ...             ...   \n",
       "1442  ...          -115.0       4.34            0.13           -0.10   \n",
       "1443  ...          -232.0       4.47            0.06           -0.21   \n",
       "1444  ...          -232.0       4.47            0.06           -0.21   \n",
       "1445  ...           -87.0       4.46            0.04           -0.12   \n",
       "1446  ...          -107.0       4.51            0.05           -0.08   \n",
       "\n",
       "      koi_srad  koi_srad_err1  koi_srad_err2      ra    dec  koi_kepmag  \n",
       "0         0.93           0.11          -0.06  291.93  48.14       15.35  \n",
       "1         0.93           0.11          -0.06  291.93  48.14       15.35  \n",
       "2         0.87           0.23          -0.08  297.00  48.13       15.44  \n",
       "3         0.79           0.20          -0.07  285.53  48.29       15.60  \n",
       "4         1.05           0.33          -0.13  288.75  48.23       15.51  \n",
       "...        ...            ...            ...     ...    ...         ...  \n",
       "1442      1.10           0.17          -0.16  287.14  47.12       12.78  \n",
       "1443      1.00           0.33          -0.11  288.01  46.12       15.21  \n",
       "1444      1.00           0.33          -0.11  288.01  46.12       15.21  \n",
       "1445      0.99           0.15          -0.07  289.04  42.88       12.99  \n",
       "1446      0.86           0.09          -0.05  295.18  49.95       13.80  \n",
       "\n",
       "[1447 rows x 46 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8ac7874",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "kepid                  0\n",
       "kepoi_name             0\n",
       "kepler_name          641\n",
       "koi_disposition        0\n",
       "koi_pdisposition       0\n",
       "koi_score              0\n",
       "koi_fpflag_nt          0\n",
       "koi_fpflag_ss          0\n",
       "koi_fpflag_co          0\n",
       "koi_fpflag_ec          0\n",
       "koi_period             0\n",
       "koi_period_err1        0\n",
       "koi_period_err2        0\n",
       "koi_time0bk            0\n",
       "koi_time0bk_err1       0\n",
       "koi_time0bk_err2       0\n",
       "koi_impact             0\n",
       "koi_impact_err1        0\n",
       "koi_impact_err2        0\n",
       "koi_duration           0\n",
       "koi_duration_err1      0\n",
       "koi_duration_err2      0\n",
       "koi_depth              0\n",
       "koi_depth_err1         0\n",
       "koi_depth_err2         0\n",
       "koi_prad               0\n",
       "koi_prad_err1          0\n",
       "koi_prad_err2          0\n",
       "koi_teq                0\n",
       "koi_insol              0\n",
       "koi_insol_err1         0\n",
       "koi_insol_err2         0\n",
       "koi_model_snr          0\n",
       "koi_tce_plnt_num       0\n",
       "koi_steff              0\n",
       "koi_steff_err1         0\n",
       "koi_steff_err2         0\n",
       "koi_slogg              0\n",
       "koi_slogg_err1         0\n",
       "koi_slogg_err2         0\n",
       "koi_srad               0\n",
       "koi_srad_err1          0\n",
       "koi_srad_err2          0\n",
       "ra                     0\n",
       "dec                    0\n",
       "koi_kepmag             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e2d6cce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>koi_time0bk</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.447000e+03</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "      <td>1447.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.700873e+06</td>\n",
       "      <td>0.696638</td>\n",
       "      <td>0.023497</td>\n",
       "      <td>0.199724</td>\n",
       "      <td>0.161023</td>\n",
       "      <td>0.098825</td>\n",
       "      <td>119.361175</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>-0.000049</td>\n",
       "      <td>170.868127</td>\n",
       "      <td>...</td>\n",
       "      <td>-143.895994</td>\n",
       "      <td>4.406256</td>\n",
       "      <td>0.089846</td>\n",
       "      <td>-0.123301</td>\n",
       "      <td>1.271819</td>\n",
       "      <td>0.247001</td>\n",
       "      <td>-0.231184</td>\n",
       "      <td>292.114610</td>\n",
       "      <td>43.837865</td>\n",
       "      <td>14.623898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.711469e+06</td>\n",
       "      <td>0.435988</td>\n",
       "      <td>0.151528</td>\n",
       "      <td>0.399931</td>\n",
       "      <td>0.367679</td>\n",
       "      <td>0.298530</td>\n",
       "      <td>3418.120272</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>0.000787</td>\n",
       "      <td>65.505885</td>\n",
       "      <td>...</td>\n",
       "      <td>65.447183</td>\n",
       "      <td>0.315693</td>\n",
       "      <td>0.088611</td>\n",
       "      <td>0.073877</td>\n",
       "      <td>3.815287</td>\n",
       "      <td>0.807914</td>\n",
       "      <td>1.270791</td>\n",
       "      <td>4.699161</td>\n",
       "      <td>3.647025</td>\n",
       "      <td>1.210683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.574500e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.290000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.020000</td>\n",
       "      <td>120.570000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1005.000000</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.750000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-33.660000</td>\n",
       "      <td>280.360000</td>\n",
       "      <td>36.580000</td>\n",
       "      <td>6.970000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.559550e+06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.720000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>134.475000</td>\n",
       "      <td>...</td>\n",
       "      <td>-179.000000</td>\n",
       "      <td>4.340000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>-0.180000</td>\n",
       "      <td>0.810000</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>-0.150000</td>\n",
       "      <td>288.790000</td>\n",
       "      <td>40.765000</td>\n",
       "      <td>13.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.939330e+06</td>\n",
       "      <td>0.997000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.510000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>142.190000</td>\n",
       "      <td>...</td>\n",
       "      <td>-142.000000</td>\n",
       "      <td>4.470000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>-0.110000</td>\n",
       "      <td>0.930000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>-0.090000</td>\n",
       "      <td>292.470000</td>\n",
       "      <td>43.730000</td>\n",
       "      <td>15.040000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>9.897461e+06</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>21.040000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>173.550000</td>\n",
       "      <td>...</td>\n",
       "      <td>-90.000000</td>\n",
       "      <td>4.560000</td>\n",
       "      <td>0.120000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>1.155000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>-0.060000</td>\n",
       "      <td>295.895000</td>\n",
       "      <td>46.750000</td>\n",
       "      <td>15.470000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.264482e+07</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>129995.780000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>524.280000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.280000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>101.450000</td>\n",
       "      <td>20.710000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>301.480000</td>\n",
       "      <td>51.760000</td>\n",
       "      <td>17.450000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 42 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              kepid    koi_score  koi_fpflag_nt  koi_fpflag_ss  koi_fpflag_co  \\\n",
       "count  1.447000e+03  1447.000000    1447.000000    1447.000000    1447.000000   \n",
       "mean   7.700873e+06     0.696638       0.023497       0.199724       0.161023   \n",
       "std    2.711469e+06     0.435988       0.151528       0.399931       0.367679   \n",
       "min    7.574500e+05     0.000000       0.000000       0.000000       0.000000   \n",
       "25%    5.559550e+06     0.000000       0.000000       0.000000       0.000000   \n",
       "50%    7.939330e+06     0.997000       0.000000       0.000000       0.000000   \n",
       "75%    9.897461e+06     1.000000       0.000000       0.000000       0.000000   \n",
       "max    1.264482e+07     1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       koi_fpflag_ec     koi_period  koi_period_err1  koi_period_err2  \\\n",
       "count    1447.000000    1447.000000      1447.000000      1447.000000   \n",
       "mean        0.098825     119.361175         0.000049        -0.000049   \n",
       "std         0.298530    3418.120272         0.000787         0.000787   \n",
       "min         0.000000       0.290000         0.000000        -0.020000   \n",
       "25%         0.000000       3.720000         0.000000         0.000000   \n",
       "50%         0.000000       8.510000         0.000000         0.000000   \n",
       "75%         0.000000      21.040000         0.000000         0.000000   \n",
       "max         1.000000  129995.780000         0.020000         0.000000   \n",
       "\n",
       "       koi_time0bk  ...  koi_steff_err2    koi_slogg  koi_slogg_err1  \\\n",
       "count  1447.000000  ...     1447.000000  1447.000000     1447.000000   \n",
       "mean    170.868127  ...     -143.895994     4.406256        0.089846   \n",
       "std      65.505885  ...       65.447183     0.315693        0.088611   \n",
       "min     120.570000  ...    -1005.000000     0.650000        0.000000   \n",
       "25%     134.475000  ...     -179.000000     4.340000        0.040000   \n",
       "50%     142.190000  ...     -142.000000     4.470000        0.060000   \n",
       "75%     173.550000  ...      -90.000000     4.560000        0.120000   \n",
       "max     524.280000  ...        0.000000     5.280000        0.920000   \n",
       "\n",
       "       koi_slogg_err2     koi_srad  koi_srad_err1  koi_srad_err2           ra  \\\n",
       "count     1447.000000  1447.000000    1447.000000    1447.000000  1447.000000   \n",
       "mean        -0.123301     1.271819       0.247001      -0.231184   292.114610   \n",
       "std          0.073877     3.815287       0.807914       1.270791     4.699161   \n",
       "min         -0.750000     0.120000       0.000000     -33.660000   280.360000   \n",
       "25%         -0.180000     0.810000       0.080000      -0.150000   288.790000   \n",
       "50%         -0.110000     0.930000       0.190000      -0.090000   292.470000   \n",
       "75%         -0.060000     1.155000       0.280000      -0.060000   295.895000   \n",
       "max          0.000000   101.450000      20.710000       0.000000   301.480000   \n",
       "\n",
       "               dec   koi_kepmag  \n",
       "count  1447.000000  1447.000000  \n",
       "mean     43.837865    14.623898  \n",
       "std       3.647025     1.210683  \n",
       "min      36.580000     6.970000  \n",
       "25%      40.765000    13.960000  \n",
       "50%      43.730000    15.040000  \n",
       "75%      46.750000    15.470000  \n",
       "max      51.760000    17.450000  \n",
       "\n",
       "[8 rows x 42 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9fadb6f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1447 entries, 0 to 1446\n",
      "Data columns (total 46 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   kepid              1447 non-null   int64  \n",
      " 1   kepoi_name         1447 non-null   object \n",
      " 2   kepler_name        806 non-null    object \n",
      " 3   koi_disposition    1447 non-null   object \n",
      " 4   koi_pdisposition   1447 non-null   object \n",
      " 5   koi_score          1447 non-null   float64\n",
      " 6   koi_fpflag_nt      1447 non-null   int64  \n",
      " 7   koi_fpflag_ss      1447 non-null   int64  \n",
      " 8   koi_fpflag_co      1447 non-null   int64  \n",
      " 9   koi_fpflag_ec      1447 non-null   int64  \n",
      " 10  koi_period         1447 non-null   float64\n",
      " 11  koi_period_err1    1447 non-null   float64\n",
      " 12  koi_period_err2    1447 non-null   float64\n",
      " 13  koi_time0bk        1447 non-null   float64\n",
      " 14  koi_time0bk_err1   1447 non-null   float64\n",
      " 15  koi_time0bk_err2   1447 non-null   float64\n",
      " 16  koi_impact         1447 non-null   float64\n",
      " 17  koi_impact_err1    1447 non-null   float64\n",
      " 18  koi_impact_err2    1447 non-null   float64\n",
      " 19  koi_duration       1447 non-null   float64\n",
      " 20  koi_duration_err1  1447 non-null   float64\n",
      " 21  koi_duration_err2  1447 non-null   float64\n",
      " 22  koi_depth          1447 non-null   float64\n",
      " 23  koi_depth_err1     1447 non-null   float64\n",
      " 24  koi_depth_err2     1447 non-null   float64\n",
      " 25  koi_prad           1447 non-null   float64\n",
      " 26  koi_prad_err1      1447 non-null   float64\n",
      " 27  koi_prad_err2      1447 non-null   float64\n",
      " 28  koi_teq            1447 non-null   float64\n",
      " 29  koi_insol          1447 non-null   float64\n",
      " 30  koi_insol_err1     1447 non-null   float64\n",
      " 31  koi_insol_err2     1447 non-null   float64\n",
      " 32  koi_model_snr      1447 non-null   float64\n",
      " 33  koi_tce_plnt_num   1447 non-null   float64\n",
      " 34  koi_steff          1447 non-null   float64\n",
      " 35  koi_steff_err1     1447 non-null   float64\n",
      " 36  koi_steff_err2     1447 non-null   float64\n",
      " 37  koi_slogg          1447 non-null   float64\n",
      " 38  koi_slogg_err1     1447 non-null   float64\n",
      " 39  koi_slogg_err2     1447 non-null   float64\n",
      " 40  koi_srad           1447 non-null   float64\n",
      " 41  koi_srad_err1      1447 non-null   float64\n",
      " 42  koi_srad_err2      1447 non-null   float64\n",
      " 43  ra                 1447 non-null   float64\n",
      " 44  dec                1447 non-null   float64\n",
      " 45  koi_kepmag         1447 non-null   float64\n",
      "dtypes: float64(37), int64(5), object(4)\n",
      "memory usage: 520.1+ KB\n"
     ]
    }
   ],
   "source": [
    "df_filled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "26613ad3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CONFIRMED', 'CANDIDATE', 'FALSE POSITIVE'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled[\"koi_disposition\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83ded3d4",
   "metadata": {},
   "source": [
    "Encoding the Categorical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7dfdcdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled.replace({'koi_disposition' : {'CONFIRMED':1,'CANDIDATE':2,'FALSE POSITIVE':0}},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cc5140f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled[\"koi_disposition\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "889ef2d1",
   "metadata": {},
   "source": [
    "Dropping some categorical features which are not not having any connections or correlations for the classification purposes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "54cdcb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = df_filled.drop([\"kepoi_name\",\"kepler_name\",\"koi_pdisposition\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5c8b3c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kepid</th>\n",
       "      <th>koi_disposition</th>\n",
       "      <th>koi_score</th>\n",
       "      <th>koi_fpflag_nt</th>\n",
       "      <th>koi_fpflag_ss</th>\n",
       "      <th>koi_fpflag_co</th>\n",
       "      <th>koi_fpflag_ec</th>\n",
       "      <th>koi_period</th>\n",
       "      <th>koi_period_err1</th>\n",
       "      <th>koi_period_err2</th>\n",
       "      <th>...</th>\n",
       "      <th>koi_steff_err2</th>\n",
       "      <th>koi_slogg</th>\n",
       "      <th>koi_slogg_err1</th>\n",
       "      <th>koi_slogg_err2</th>\n",
       "      <th>koi_srad</th>\n",
       "      <th>koi_srad_err1</th>\n",
       "      <th>koi_srad_err2</th>\n",
       "      <th>ra</th>\n",
       "      <th>dec</th>\n",
       "      <th>koi_kepmag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10797460</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>291.93</td>\n",
       "      <td>48.14</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10797460</td>\n",
       "      <td>1</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54.42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-81.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.11</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>291.93</td>\n",
       "      <td>48.14</td>\n",
       "      <td>15.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10811496</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19.90</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-176.0</td>\n",
       "      <td>4.54</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.23</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>297.00</td>\n",
       "      <td>48.13</td>\n",
       "      <td>15.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10848459</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-174.0</td>\n",
       "      <td>4.56</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.17</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.20</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>285.53</td>\n",
       "      <td>48.29</td>\n",
       "      <td>15.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10854555</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.53</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-211.0</td>\n",
       "      <td>4.44</td>\n",
       "      <td>0.07</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>288.75</td>\n",
       "      <td>48.23</td>\n",
       "      <td>15.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>10130039</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.47</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-115.0</td>\n",
       "      <td>4.34</td>\n",
       "      <td>0.13</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.17</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>287.14</td>\n",
       "      <td>47.12</td>\n",
       "      <td>12.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>9518318</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>288.01</td>\n",
       "      <td>46.12</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>9518318</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-232.0</td>\n",
       "      <td>4.47</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.21</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>288.01</td>\n",
       "      <td>46.12</td>\n",
       "      <td>15.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1445</th>\n",
       "      <td>7273277</td>\n",
       "      <td>1</td>\n",
       "      <td>0.998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.71</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-87.0</td>\n",
       "      <td>4.46</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.12</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>289.04</td>\n",
       "      <td>42.88</td>\n",
       "      <td>12.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1446</th>\n",
       "      <td>11769890</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>122.88</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-107.0</td>\n",
       "      <td>4.51</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.09</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>295.18</td>\n",
       "      <td>49.95</td>\n",
       "      <td>13.80</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1447 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         kepid  koi_disposition  koi_score  koi_fpflag_nt  koi_fpflag_ss  \\\n",
       "0     10797460                1      1.000              0              0   \n",
       "1     10797460                1      0.969              0              0   \n",
       "2     10811496                2      0.000              0              0   \n",
       "3     10848459                0      0.000              0              1   \n",
       "4     10854555                1      1.000              0              0   \n",
       "...        ...              ...        ...            ...            ...   \n",
       "1442  10130039                1      1.000              0              0   \n",
       "1443   9518318                1      1.000              0              0   \n",
       "1444   9518318                1      1.000              0              0   \n",
       "1445   7273277                1      0.998              0              0   \n",
       "1446  11769890                1      1.000              0              0   \n",
       "\n",
       "      koi_fpflag_co  koi_fpflag_ec  koi_period  koi_period_err1  \\\n",
       "0                 0              0        9.49              0.0   \n",
       "1                 0              0       54.42              0.0   \n",
       "2                 0              0       19.90              0.0   \n",
       "3                 0              0        1.74              0.0   \n",
       "4                 0              0        2.53              0.0   \n",
       "...             ...            ...         ...              ...   \n",
       "1442              0              0        5.47              0.0   \n",
       "1443              0              0        6.51              0.0   \n",
       "1444              0              0       23.85              0.0   \n",
       "1445              0              0        2.71              0.0   \n",
       "1446              0              0      122.88              0.0   \n",
       "\n",
       "      koi_period_err2  ...  koi_steff_err2  koi_slogg  koi_slogg_err1  \\\n",
       "0                 0.0  ...           -81.0       4.47            0.06   \n",
       "1                 0.0  ...           -81.0       4.47            0.06   \n",
       "2                 0.0  ...          -176.0       4.54            0.04   \n",
       "3                 0.0  ...          -174.0       4.56            0.05   \n",
       "4                 0.0  ...          -211.0       4.44            0.07   \n",
       "...               ...  ...             ...        ...             ...   \n",
       "1442              0.0  ...          -115.0       4.34            0.13   \n",
       "1443              0.0  ...          -232.0       4.47            0.06   \n",
       "1444              0.0  ...          -232.0       4.47            0.06   \n",
       "1445              0.0  ...           -87.0       4.46            0.04   \n",
       "1446              0.0  ...          -107.0       4.51            0.05   \n",
       "\n",
       "      koi_slogg_err2  koi_srad  koi_srad_err1  koi_srad_err2      ra    dec  \\\n",
       "0              -0.10      0.93           0.11          -0.06  291.93  48.14   \n",
       "1              -0.10      0.93           0.11          -0.06  291.93  48.14   \n",
       "2              -0.18      0.87           0.23          -0.08  297.00  48.13   \n",
       "3              -0.17      0.79           0.20          -0.07  285.53  48.29   \n",
       "4              -0.21      1.05           0.33          -0.13  288.75  48.23   \n",
       "...              ...       ...            ...            ...     ...    ...   \n",
       "1442           -0.10      1.10           0.17          -0.16  287.14  47.12   \n",
       "1443           -0.21      1.00           0.33          -0.11  288.01  46.12   \n",
       "1444           -0.21      1.00           0.33          -0.11  288.01  46.12   \n",
       "1445           -0.12      0.99           0.15          -0.07  289.04  42.88   \n",
       "1446           -0.08      0.86           0.09          -0.05  295.18  49.95   \n",
       "\n",
       "      koi_kepmag  \n",
       "0          15.35  \n",
       "1          15.35  \n",
       "2          15.44  \n",
       "3          15.60  \n",
       "4          15.51  \n",
       "...          ...  \n",
       "1442       12.78  \n",
       "1443       15.21  \n",
       "1444       15.21  \n",
       "1445       12.99  \n",
       "1446       13.80  \n",
       "\n",
       "[1447 rows x 43 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdf7277",
   "metadata": {},
   "source": [
    "# Random Forest Classifier Algorithms Implemtation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bbb08dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score,classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1288010",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4017f51",
   "metadata": {},
   "source": [
    "Selecting the Independent and the Dependent Variables before loading into the models for Classification and GridSearchCV Tunning method is used for increasing the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "27f779c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={&#x27;max_depth&#x27;: [None, 10, 20],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
       "                         &#x27;n_estimators&#x27;: [50, 100, 200]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(),\n",
       "             param_grid={'max_depth': [None, 10, 20],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10],\n",
       "                         'n_estimators': [50, 100, 200]},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV \n",
    "\n",
    "X = df_filled.drop(\"koi_disposition\", axis=1)\n",
    "Y = df_filled[\"koi_disposition\"]\n",
    "\n",
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state = 42)\n",
    "\n",
    "param_grid_rf = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "rf_clf_model = RandomForestClassifier()\n",
    "\n",
    "grid_search_rf = GridSearchCV(rf_clf_model, param_grid_rf, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search_rf.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cceab89",
   "metadata": {},
   "source": [
    "Printing the best parameters being chosen by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b58d87f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search_rf.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5045317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_rf.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43411a11",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9bb7a446",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8655172413793103\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94        81\n",
      "           1       0.87      0.96      0.91       167\n",
      "           2       0.61      0.26      0.37        42\n",
      "\n",
      "    accuracy                           0.87       290\n",
      "   macro avg       0.80      0.73      0.74       290\n",
      "weighted avg       0.84      0.87      0.84       290\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 79   0   2]\n",
      " [  1 161   5]\n",
      " [  7  24  11]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_rf = accuracy_score(Y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy_rf)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, y_pred))\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ecf7db",
   "metadata": {},
   "source": [
    "# Logistic Regression Algorithms Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b873c94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d746c375",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_filled.drop(\"koi_disposition\", axis=1)\n",
    "y = df_filled[\"koi_disposition\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06239092",
   "metadata": {},
   "source": [
    "Here also , GridSearchCV tunning method is used to increase the model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f0c49b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42)\n",
    "\n",
    "param_grid_lr = {\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "model_lr = LogisticRegression()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "681fefd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:425: FitFailedWarning: \n",
      "30 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "30 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:979: UserWarning: One or more of the test scores are non-finite: [      nan 0.6603299       nan 0.6637931       nan 0.6629273       nan\n",
      " 0.6629273       nan 0.6629273       nan 0.6629273]\n",
      "  warnings.warn(\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" ><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={&#x27;C&#x27;: [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;]},\n",
       "             scoring=&#x27;accuracy&#x27;)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search_lr = GridSearchCV(model_lr, param_grid_lr, cv=5, scoring='accuracy')\n",
    "\n",
    "grid_search_lr.fit(X_train, Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c140d",
   "metadata": {},
   "source": [
    "Best parameters which are selected by the model being printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c614bc9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.01, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "best_params = grid_search_lr.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e2fc1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search_lr.best_estimator_\n",
    "y_prediction = best_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82727bd",
   "metadata": {},
   "source": [
    "Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1278a8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6896551724137931\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.56      0.61        81\n",
      "           1       0.70      0.93      0.79       167\n",
      "           2       0.00      0.00      0.00        42\n",
      "\n",
      "    accuracy                           0.69       290\n",
      "   macro avg       0.46      0.49      0.47       290\n",
      "weighted avg       0.59      0.69      0.63       290\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 45  36   0]\n",
      " [ 12 155   0]\n",
      " [ 10  32   0]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/soumobratamanna/miniforge3/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "accuracy_lr = accuracy_score(Y_test, y_prediction)\n",
    "print(\"Accuracy:\", accuracy_lr)\n",
    "\n",
    "\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(Y_test, y_prediction))\n",
    "\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(Y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11628704",
   "metadata": {},
   "source": [
    "Data Visualization on Accuracy Scores , comparing both the Algorithms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8834a4d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "algorithms=[\"Random Forest Classifier\", \"Logistic Regression\"]\n",
    "accuracy_scores=[accuracy_rf,accuracy_lr]\n",
    "plt.plot(algorithms,accuracy_scores, marker = 'o',color='red')\n",
    "plt.grid()\n",
    "plt.title(\"Accuracy Score Value Comparison\") \n",
    "plt.xlabel(\"Algorithms\")\n",
    "plt.ylabel(\"Accuracy Scores\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6d2018",
   "metadata": {},
   "source": [
    "From the above Comparison Graph it is observed that Random Forest Classifier outperform Logistic Regression for classification problems for several reasons:\n",
    "\n",
    ">Handling Nonlinear Relationships:Random Forest is capable of capturing nonlinear relationships between features and target variables. It constructs multiple decision trees and combines their predictions, allowing it to model complex decision boundaries. In contrast, Logistic Regression assumes linear relationships between features and the log-odds of the target variable, which may limit its ability to capture nonlinear patterns in the data.\n",
    "\n",
    ">Robustness to Outliers and Irrelevant Features:Random Forest is less sensitive to outliers and irrelevant features compared to Logistic Regression. Since it averages predictions from multiple decision trees, outliers and noise in the data have less impact on the final result. Logistic Regression, on the other hand, may be influenced by outliers and may assign undue importance to irrelevant features.\n",
    "\n",
    "> Feature Importance:Random Forest provides a measure of feature importance, indicating which features contribute most to the classification task. This information can be valuable for feature selection and interpretation. Logistic Regression, while interpretable, does not inherently provide feature importance measures.\n",
    "\n",
    "> Ensemble Learning:Random Forest is an ensemble learning method, combining multiple decision trees to improve predictive performance. Each decision tree is trained independently on a subset of the data, and their predictions are aggregated to make final predictions. This ensemble approach helps reduce overfitting and variance, leading to better generalization performance compared to Logistic Regression, especially when the dataset is complex or high-dimensional.\n",
    "\n",
    "> Handling Imbalanced Data: Random Forest can handle imbalanced datasets more effectively than Logistic Regression. By randomly sampling from the majority and minority classes during the construction of each decision tree, Random Forest can mitigate the impact of class imbalance. Logistic Regression, while possible to use with imbalanced data, may require additional techniques such as class weighting or resampling to address class imbalance effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "093a2dcc",
   "metadata": {},
   "source": [
    "# Business Questions "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a049748",
   "metadata": {},
   "source": [
    "Sub-questions for Problem 2\n",
    "1. Why did you choose the particular algorithm?\n",
    "2. What are the different tuning methods used for the algorithm?\n",
    "3. Did you consider any other choice of algorithm?Why or why not?\n",
    "4. What is the accuracy?\n",
    "5. What are the different types of metrics that can be used to evaluate the model?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c325631",
   "metadata": {},
   "source": [
    "1. Why did you choose the particular algorithm?\n",
    "> Random Forest Classifier algorithm is implemented as the first choice of algorithm because it has higher accuracy as compared to other classification algorithms, non-linear relationships, it's robustness to overfitting, feature importance, handling imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cdcd1d",
   "metadata": {},
   "source": [
    "2. What are the different tuning methods used for the algorithm?\n",
    "> GridSearchCV Tuning method is used on both the algorithms with some hyperparameters testing and printed the best parameters being chosen by the model with the values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d256547a",
   "metadata": {},
   "source": [
    "3. Did you consider any other choice of algorithm?Why or why not?\n",
    "> Yes, Logistic Regression Algorithms is used for classification purposes but the accuracy score is better for Random Forest Classifier algorithm due to multiple reasons mentioned above after graph implementation\n",
    "\n",
    ">Even planned of using Naive Bayes Algorithms but it has no tunning methods , its a pretty generalized model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf3310c",
   "metadata": {},
   "source": [
    "4. What is the accuracy?\n",
    "> Random Forest Classifier - 0.86\n",
    "\n",
    "> Logistic Regression - 0.68\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d347d472",
   "metadata": {},
   "source": [
    "5. What are the different types of metrics that can be used to evaluate the model?\n",
    "> Metrics used are Accuracy, Confusion matrix and Classification Report for evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fd2d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57449c5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
